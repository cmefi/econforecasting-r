# Set Constants
```{r}
DIR = 'D:/Onedrive/__Projects/econforecasting'
DL_DIR = 'D:/Onedrive/__Projects/econforecasting/tmp'
PACKAGE_DIR = 'D:/Onedrive/__Projects/econforecasting/r-package' # Path to package with helper functions
INPUT_DIR = 'D:/Onedrive/__Projects/econforecasting/model-inputs' # Path to directory with constants.r (SQL DB info, SFTP info, etc.)
RESET_ALL = FALSE
```


# Initialize
```{r}
library(tidyverse)
library(data.table)
library(devtools)
library(jsonlite)
library(lubridate)
library(httr)
library(rvest)
library(DBI)
devtools::load_all(path = PACKAGE_DIR)
devtools::document(PACKAGE_DIR)

setwd(DIR)

if (dir.exists(DL_DIR)) unlink(DL_DIR, recursive = TRUE)
dir.create(DL_DIR, recursive = TRUE)

source(file.path(INPUT_DIR, 'constants.r'))

ef = list(
	variablesDf = readxl::read_excel(file.path(INPUT_DIR, 'inputs.xlsx'), sheet = 'baseline-variables'),
	forecastsDf = readxl::read_excel(file.path(INPUT_DIR, 'inputs.xlsx'), sheet = 'baseline-forecasts'),
	h = list(),
	f = list()
	) %>%
	c(., list(variables = purrr::transpose(.$variablesDf, .names = .$variablesDf$varname)))
```



# Get Historical Data

## FRED
```{r}
local({
	
	fredRes =
		ef$variables %>%
		purrr::keep(., ~ .$source == 'fred') %>%
		lapply(., function(x) {
			
			message('Getting data ... ', x$varname)

			# Get series data
			dataDf =
				econforecasting::getDataFred(x$sckey, CONST$FRED_API_KEY, .freq = x$freq) %>%
				dplyr::transmute(., varname = x$varname, date = obsDate, freq = x$freq, value) %>%
				dplyr::filter(., date >= as.Date('2010-01-01'))

				# list(
				# 	q = econforecasting::getDataFred(x$sckey, CONST$FRED_API_KEY, .freq = x$freq),
				# 	m =	{if (x$freq %in% c('d', 'w', 'm')) econforecasting::getDataFred(x$sckey, CONST$FRED_API_KEY, .freq = 'm') else NA},
				# 	w =	{if (x$freq %in% c('d', 'w')) econforecasting::getDataFred(x$sckey, CONST$FRED_API_KEY, .freq = 'w') else NA},
				# 	d =	{if (x$freq %in% c('d')) econforecasting::getDataFred(x$sckey, CONST$FRED_API_KEY, .freq = 'd') else NA}
				# 	) %>%
				# purrr::keep(., ~ is_tibble(.)) %>%
				# purrr::imap(., function(df, i)
				# 	df %>%
				# 		dplyr::transmute(., varname = x$varname, date = obsDate, freq = i, value) %>%
				# 		dplyr::filter(., date >= as.Date('2010-01-01'))
				# 	)
			
			# Get series release
			releaseDf =
				httr::RETRY(
					'GET', 
					paste0(
						'https://api.stlouisfed.org/fred/series/release?',
						'series_id=',x$sckey,'&api_key=',CONST$FRED_API_KEY,'&file_type=json'
						),
					times = 10
				) %>%
		        httr::content(., as = 'parsed') %>%
				.$releases %>%
				.[[1]] %>%
				as_tibble(.) %>%
				dplyr::mutate(., varname = x$varname)

			list(dataDf = dataDf, releaseDf = releaseDf)
			})
	
	
	for (varname in names(fredRes)) {
		ef$variables[[varname]]$rawData <<- fredRes[[varname]]$dataDf
		ef$variables[[varname]]$releasekey <<- fredRes[[varname]]$releaseDf$id
	}
})
```

## Yahoo Finance
```{r}
local({
	
	res =
		ef$variables %>%
    	purrr::keep(., ~ .$source == 'yahoo') %>%
		lapply(., function(x) {
			url =
				paste0(
					'https://query1.finance.yahoo.com/v7/finance/download/', x$sckey,
					'?period1=', '946598400', # 12/30/1999
					'&period2=', as.numeric(as.POSIXct(Sys.Date() + lubridate::days(1))),
					'&interval=1d',
					'&events=history&includeAdjustedClose=true'
				)
			data.table::fread(url, showProgress = FALSE) %>%
				.[, c('Date', 'Adj Close')]	%>%
				setnames(., new = c('date', 'value')) %>%
				as_tibble(.) %>%
				dplyr::mutate(., varname = x$varname, freq = 'd') %>%
				return(.)
		})
	
	for (varname in names(res)) {
		ef$variables[[varname]]$rawData <<- res[[varname]]
	}
})
```



# Aggregate Frequencies

## Move to Hist Object
```{r}
local({
	
	 res =
	 	ef$variables %>%
	 	purrr::keep(., ~ is_tibble(.$rawData)) %>%
	 	lapply(., function(x)
	 		list(x$rawData) %>%
	 			setNames(., x$freq)
	 		)
	 
	for (varname in names(res)) {
		ef$variables[[varname]]$h$base <<- res[[varname]]
	}
})
```

## Monthly Agg
```{r}
local({
	
    res =
        # Get all daily/weekly varnames with pre-existing data
        ef$variables %>%
        purrr::keep(., ~ .$freq %in% c('d', 'w') && is_tibble(.$rawData)) %>%
        # Add monthly values for current month
        lapply(., function(x) {
        	x$rawData %>%
        		dplyr::mutate(., date = as.Date(paste0(year(date), '-', month(date), '-01'))) %>%
        		dplyr::group_by(., date, varname) %>%
        		dplyr::summarize(., value = mean(value), .groups = 'drop') %>%
        		dplyr::mutate(., freq = 'm') %>%
        		{
        			# Keep last-month aggregation despite possible mising data if set in inputs.xlsx
        			if (x$append_eom_with_currentval == 1) .
        			else dplyr::filter(., date != max(date))
        		}
        	})
    
	for (varname in names(res)) {
		ef$variables[[varname]]$h$base$m <<- res[[varname]]
	}
})
```

## Quarterly Aggregation
```{r}
local({
	
    res =
        ef$variables %>%
        purrr::keep(., ~ .$freq %in% c('d', 'w', 'm') && is_tibble(.$rawData)) %>%
        lapply(., function(x) {
        	message(x$varname)
        	x$h$base$m %>%
        		dplyr::mutate(., date = strdateToDate(paste0(year(date), 'Q', quarter(date)))) %>%
        		dplyr::group_by(., date, varname) %>%
        		dplyr::summarize(., value = mean(value), .groups = 'drop', n = n()) %>%
        		# Only keep if all 3 monthly data exists (or imputed by previous chunk)
        		dplyr::filter(., n == 3) %>%
        		dplyr::select(., -n) %>%
        		dplyr::mutate(., freq = 'q')
        	})
    
	for (varname in names(res)) {
		ef$variables[[varname]]$h$base$q <<- res[[varname]]
	}
    
})
```



# Add Calculated Variables

## Trailing Inflation
```{r}
local({
	
	mDf =
		ef$variables$cpi$h$base$m %>%
    	dplyr::mutate(., value = (value/dplyr::lag(value, 13) - 1) * 100) %>%
    	dplyr::mutate(., varname = 'inf') %>%
		na.omit(.)
	
	qDf =
		mDf %>%
		dplyr::mutate(., date = strdateToDate(paste0(year(date), 'Q', quarter(date)))) %>%
	    dplyr::group_by(., date, varname) %>%
	    dplyr::summarize(., value = mean(value), .groups = 'drop', n = n()) %>%
	    # Only keep if all 3 monthly data exists (or imputed by previous chunk)
	    dplyr::filter(., n == 3) %>%
	    dplyr::select(., -n) %>%
	    dplyr::mutate(., freq = 'q')
	
	ef$variables$inf$h$base$m <<- mDf
	ef$variables$inf$h$base$q <<- qDf
})
```


## DNS Model - Interest Rates
Let tyield = rrfr + dns_curve(ttm)
Exogenously choose ffr and tyield_10y_3m (negative of 10year - 3month spread; 3-month driven heavily by ffr)
```{r}
local({
  
  # Create tibble mapping tyield_3m to 3, tyield_1y to 12, etc.
  yieldCurveNamesMap =
    ef$variables %>% 
    map_chr(., ~.$varname) %>%
    unique(.) %>%
    purrr::keep(., ~ str_sub(., 1, 1) == 't' & str_length(.) == 4) %>%
    tibble(varname = .) %>%
    dplyr::mutate(., ttm = as.numeric(str_sub(varname, 2, 3)) * ifelse(str_sub(varname, 4, 4) == 'y', 12, 1))
  
  # Create training dataset from SPREAD from ffr - fitted on last 3 months
  trainDf =
	map_dfr(yieldCurveNamesMap$varname, function(x) ef$variables[[x]]$h$base$m) %>%
  	dplyr::select(., -freq) %>%
  	dplyr::filter(., date >= add_with_rollback(Sys.Date(), months(-3))) %>%
    dplyr::right_join(., yieldCurveNamesMap, by = 'varname') %>%
    dplyr::left_join(., dplyr::transmute(ef$variables$ffr$h$base$m, date, ffr = value), by = 'date') %>%
  	dplyr::mutate(., value = value - ffr) %>%
  	dplyr::select(., -ffr)
  
  # @param df: (tibble) A tibble continuing columns obsDate, value, and ttm
  # @param returnAll: (boolean) FALSE by default.
  # If FALSE, will return only the MAPE (useful for optimization).
  # Otherwise, will return a tibble containing fitted values, residuals, and the beta coefficients.
  getDnsFit = function(df, lambda, returnAll = FALSE) {
    df %>%
      dplyr::mutate(
        .,
        f1 = 1,
        f2 = (1 - exp(-1 * lambda * ttm))/(lambda * ttm),
        f3 = f2 - exp(-1 * lambda * ttm)
        ) %>%
      dplyr::group_by(date) %>%
      dplyr::group_split(.) %>%
      lapply(., function(x) {
        reg = lm(value ~ f1 + f2 + f3 - 1, data = x)
        dplyr::bind_cols(x, fitted = fitted(reg)) %>%
          dplyr::mutate(., b1 = coef(reg)[['f1']], b2 = coef(reg)[['f2']], b3 = coef(reg)[['f3']]) %>%
          dplyr::mutate(., resid = value - fitted)
        }) %>%
      dplyr::bind_rows(.) %>%
      {
        if (returnAll == FALSE) dplyr::summarise(., mae = mean(abs(resid))) %>% .$mae
        else .
        } %>%
      return(.)
  }

  # Find MAPE-minimizing lambda value
  optimLambda =
    optimize(
      getDnsFit,
      df = trainDf,
      returnAll = FALSE,
      interval = c(-1, 1),
      maximum = FALSE
      )$minimum
  
  mDf =
	map_dfr(yieldCurveNamesMap$varname, function(x) ef$variables[[x]]$h$base$m) %>%
    dplyr::select(., -freq) %>%
    dplyr::right_join(., yieldCurveNamesMap, by = 'varname') %>%
    dplyr::left_join(., dplyr::transmute(ef$variables$ffr$h$base$m, date, ffr = value), by = 'date') %>%
    dplyr::mutate(., value = value - ffr) %>%
    dplyr::select(., -ffr) %>%
  	getDnsFit(., lambda = optimLambda, returnAll = TRUE) %>%
  	dplyr::group_by(., date) %>%
  	dplyr::summarize(., tdns1 = unique(b1), tdns2 = unique(b2), tdns3 = unique(b3)) %>%
  	tidyr::pivot_longer(., -date, names_to = 'varname') %>%
  	dplyr::mutate(., freq = 'm')
  	
  qDf = mDf %>% monthToQuarter(.)
  
  mDfs =
  	mDf %>%
  	split(., as.factor(.$varname))
  
  qDfs =
  	qDf %>% split(., as.factor(.$varname))

  for (varname in names(mDfs)) {
	ef$variables[[varname]]$h$base$m <<- mDfs[[varname]]
	ef$variables[[varname]]$h$base$q <<- qDfs[[varname]]
  }
})
```



# Add Stationary Transformations

## 
Import D




# Download Nowcasts
Download Existing Forecasts -> Convert to "O" Types